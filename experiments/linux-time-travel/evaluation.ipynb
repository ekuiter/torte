{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install plotly pandas statsmodels kaleido scipy nbformat jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV data\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pickle\n",
    "import scipy\n",
    "from statistics import mean, stdev\n",
    "from math import sqrt, log10\n",
    "from packaging.version import Version\n",
    "\n",
    "pio.renderers.default = \"notebook\"\n",
    "output_directory = '../../output-archive/output-linux-2024-11-08'\n",
    "figures_directory = '../../../paper-icse-2026-time-travel/images'\n",
    "default_height = 270\n",
    "\n",
    "pio.templates['colorblind'] = go.layout.Template(layout_colorway=['#648FFF', '#FE6100', '#785EF0', '#DC267F', '#FFB000'])\n",
    "pio.templates.default = 'plotly_white+colorblind'\n",
    "\n",
    "def read_dataframe(stage, dtype={}, usecols=None, file=None):\n",
    "    if not file:\n",
    "        file = 'output'\n",
    "    df = pd.read_csv(f'{output_directory}/{stage}/{file}.csv', dtype=dtype, usecols=usecols)\n",
    "    if 'committer_date_unix' in df:\n",
    "        df['committer_date'] = df['committer_date_unix'].apply(lambda d: pd.to_datetime(d, unit='s'))\n",
    "    return df\n",
    "\n",
    "def replace_values(df):\n",
    "    df.replace('kconfigreader', 'KConfigReader', inplace=True)\n",
    "    df.replace('kmax', 'KClause', inplace=True)\n",
    "\n",
    "def big_log10(str):\n",
    "    return log10(int(str)) if not pd.isna(str) and str != '' else pd.NA\n",
    "\n",
    "def process_model_count(df_solve):\n",
    "    df_solve['model-count'] = df_solve['model-count'].replace('1', '')\n",
    "    df_solve['model-count-log10'] = df_solve['model-count'].fillna('').apply(big_log10).replace(0, np.nan)\n",
    "    df_solve['year'] = df_solve['committer_date'].apply(lambda d: int(d.year))\n",
    "\n",
    "def peek_dataframe(df, column, message, type='str', filter=['revision', 'architecture', 'extractor']):\n",
    "    success = df[~df[column].str.contains('NA') if type == 'str' else ~df[column].isna()][filter]\n",
    "    failure = df[df[column].str.contains('NA') if type == 'str' else df[column].isna()][filter]\n",
    "    print(f'{message}: {len(success)} successes, {len(failure)} failures')\n",
    "\n",
    "df_architectures = read_dataframe(f'read-linux-architectures')\n",
    "df_architectures = df_architectures.sort_values(by='committer_date')\n",
    "df_architectures['year'] = df_architectures['committer_date'].apply(lambda d: int(d.year))\n",
    "\n",
    "df_configs = read_dataframe(f'read-linux-configs')\n",
    "df_configs = df_configs[~df_configs['kconfig-file'].str.contains('/um/')]\n",
    "\n",
    "df_config_types = read_dataframe(f'read-linux-configs', file='output.types')\n",
    "df_config_types = df_config_types[~df_config_types['kconfig-file'].str.contains('/um/')]\n",
    "df_config_types = df_config_types.merge(df_architectures[['revision', 'committer_date']].drop_duplicates())\n",
    "\n",
    "df_kconfig = read_dataframe('kconfig')\n",
    "df_kconfig['year'] = df_kconfig['committer_date'].apply(lambda d: int(d.year))\n",
    "\n",
    "df_uvl = read_dataframe('model_to_uvl_featureide')\n",
    "df_smt = read_dataframe('model_to_smt_z3')\n",
    "df_dimacs = read_dataframe('dimacs')\n",
    "df_backbone_dimacs = read_dataframe('backbone-dimacs')\n",
    "\n",
    "df_solve = read_dataframe('solve_model-count', {'model-count': 'string'})\n",
    "process_model_count(df_solve)\n",
    "\n",
    "if os.path.isfile(f'{output_directory}/model-count-with-6h-timeout.csv'):\n",
    "    df_solve_6h = pd.read_csv(f'{output_directory}/model-count-with-6h-timeout.csv', dtype={'model-count': 'string'})\n",
    "    df_solve_6h = df_backbone_dimacs.merge(df_solve_6h)\n",
    "    process_model_count(df_solve_6h)\n",
    "    df_solve = pd.merge(df_solve, df_solve_6h[['revision','architecture', 'extractor', 'backbone.dimacs-analyzer']], indicator=True, how='outer') \\\n",
    "        .query('_merge==\"left_only\"') \\\n",
    "        .drop('_merge', axis=1)\n",
    "    df_solve = pd.concat([df_solve, df_solve_6h])\n",
    "else:\n",
    "    df_solve_6h = None\n",
    "\n",
    "for df in [df_kconfig, df_uvl, df_smt, df_dimacs, df_backbone_dimacs, df_solve]:\n",
    "    replace_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for drawing plots\n",
    "\n",
    "def estimate_group(group):\n",
    "    print('\\\\hspace{2mm} ' + group + ' \\\\\\\\')\n",
    "\n",
    "def estimate_trend(fig, color=None, color_value=None, xs=[], key=lambda x: x.timestamp()):\n",
    "    results = px.get_trendline_results(fig)\n",
    "    if color is not None and color_value is not None:\n",
    "        idx = [i for i, r in enumerate(results.iloc) if r[color] == color_value][0]\n",
    "    else:\n",
    "        idx = 0\n",
    "    intercept = results.iloc[idx]['px_fit_results'].params[0]\n",
    "    slope = results.iloc[idx]['px_fit_results'].params[1]\n",
    "    daily = slope * pd.to_timedelta(1, unit='D').total_seconds()\n",
    "    weekly = slope * pd.to_timedelta(7, unit='D').total_seconds()\n",
    "    monthly = slope * pd.to_timedelta(1, unit='D').total_seconds() * 30.437\n",
    "    yearly = slope * pd.to_timedelta(1, unit='D').total_seconds() * 365.25\n",
    "    return daily, weekly, monthly, yearly, [intercept + slope * key(x) for x in xs]\n",
    "\n",
    "def committer_date_x_axis(fig, df=df_kconfig, append_revision=True, step=1):\n",
    "    axis = df_kconfig[['committer_date', 'revision']].drop_duplicates()\n",
    "    axis['year'] = axis['committer_date'].apply(lambda d: str(d.year))\n",
    "    axis = axis.sort_values(by='committer_date').groupby('year').nth(0).reset_index()\n",
    "    fig.update_xaxes(\n",
    "        ticktext=axis['year'].str.cat('<br><sup>' + axis['revision'].str[1:] + '</sup>')[1::step] if append_revision else axis['year'][::step],\n",
    "        tickvals=axis['year'][1::step]\n",
    "    )\n",
    "\n",
    "def revision_x_axis(fig, df=df_kconfig):\n",
    "    axis = df_kconfig[['committer_date', 'revision']].drop_duplicates()\n",
    "    axis['year'] = axis['committer_date'].apply(lambda d: str(d.year))\n",
    "    axis = axis.sort_values(by='committer_date').groupby('year').nth(0).reset_index()\n",
    "    fig.update_xaxes(\n",
    "        ticktext=axis['year'],\n",
    "        tickvals=axis['revision']\n",
    "    )\n",
    "\n",
    "def log10_y_axis(fig):\n",
    "    fig.update_yaxes(tickprefix = '10<sup>', ticksuffix = '</sup>')\n",
    "\n",
    "def percentage_y_axis(fig):\n",
    "    fig.layout.yaxis.tickformat = ',.0%'\n",
    "\n",
    "def format_percentage(value):\n",
    "    return str(round(value * 100, 2)) + '%'\n",
    "\n",
    "def committer_date_labels(dict={}):\n",
    "    return {'committer_date': 'Year<br><sup>First Release in Year</sup>'} | dict\n",
    "\n",
    "def revision_labels(dict={}):\n",
    "    return {'revision': 'Year'} | dict\n",
    "\n",
    "def style_legend(fig, position='topleft', xshift=0, yshift=0):\n",
    "    if position == 'topleft':\n",
    "        fig.update_layout(legend=dict(yanchor='top', y=0.98 + yshift, xanchor='left', x=0.01 + xshift))\n",
    "    elif position == 'topright':\n",
    "        fig.update_layout(legend=dict(yanchor='top', y=0.98 + yshift, xanchor='right', x=0.98 + xshift))\n",
    "    elif position == 'bottomright':\n",
    "        fig.update_layout(legend=dict(yanchor='bottom', y=0.01 + yshift, xanchor='right', x=0.98 + xshift))\n",
    "    elif position == 'bottomleft':\n",
    "        fig.update_layout(legend=dict(yanchor='bottom', y=0.01 + yshift, xanchor='left', x=0.01 + xshift))\n",
    "    elif position == 'right':\n",
    "        return\n",
    "    elif position == 'horizontal':\n",
    "        fig.update_layout(legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1))\n",
    "    else:\n",
    "        fig.update_layout(showlegend=False)\n",
    "\n",
    "def style_box(fig, legend_position='topleft', xshift=0, yshift=0):\n",
    "    fig.update_traces(fillcolor='rgba(0,0,0,0)')\n",
    "    fig.update_traces(line_width=1)\n",
    "    fig.update_traces(marker_size=2)\n",
    "    fig.update_layout(font_family=\"Linux Biolinum\")\n",
    "    style_legend(fig, legend_position, xshift, yshift)\n",
    "\n",
    "def style_scatter(fig, marker_size=4, legend_position='topleft', xshift=0, yshift=0):\n",
    "    if marker_size:\n",
    "        fig.update_traces(marker_size=marker_size)\n",
    "    style_legend(fig, legend_position, xshift, yshift)\n",
    "    fig.update_layout(font_family=\"Linux Biolinum\")\n",
    "\n",
    "def plot_failures(fig, df, x, y, y_value, align='bottom', xref='x', font_size=10, textangle=270):\n",
    "    group = df.groupby(x, dropna=False)\n",
    "    failures = (group[y].size() - group[y].count()).reset_index().rename(columns={y: f'{y}_failures'})\n",
    "    attempts = group[y].size().reset_index().rename(columns={y: f'{y}_attempts'})\n",
    "    failures = pd.merge(failures, attempts)\n",
    "    failures[f'{y}_text'] = failures[f'{y}_failures'].astype(str) + ' (' + (failures[f'{y}_failures'] / failures[f'{y}_attempts']).apply(lambda v: \"{0:.1f}%\".format(v * 100)) + ')'\n",
    "    for row in range(len(failures)):\n",
    "        text = failures.at[row, f'{y}_text']\n",
    "        text = \"\" if failures.at[row, f'{y}_failures'] == 0 else text\n",
    "        fig.add_annotation(\n",
    "            x=failures.at[row, x],\n",
    "            y=y_value,\n",
    "            text=text,\n",
    "            showarrow=False,\n",
    "            font_size=font_size,\n",
    "            textangle=textangle,\n",
    "            align='left' if align == 'bottom' else 'right',\n",
    "            yanchor='bottom' if align == 'bottom' else 'top',\n",
    "            yshift=5 if align == 'bottom' else -5,\n",
    "            font_color='gray',\n",
    "            xref=xref\n",
    "        )\n",
    "\n",
    "def cohens_d(d1, d2):\n",
    "    # uses pooled standard deviation\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "    return (u1 - u2) / s\n",
    "\n",
    "def effect_size_mannwhitneyu(d1, d2):\n",
    "    u = scipy.stats.mannwhitneyu(d1, d2).statistic\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    n = n1 + n2\n",
    "    mean_U = n1 * n2 / 2\n",
    "    std_U = np.sqrt(n1 * n2 * (n + 1) / 12)\n",
    "    z = (u - mean_U) / std_U\n",
    "    r = z / np.sqrt(n)\n",
    "    return r\n",
    "\n",
    "def wilcoxon_test(df, column_a, column_b):\n",
    "    # if the same values are returned for many inputs, refer to https://stats.stackexchange.com/q/232927\n",
    "    a = df[column_a][~df[column_a].isna()]\n",
    "    b = df[column_b][~df[column_b].isna()]\n",
    "    d = a - b\n",
    "    results = scipy.stats.wilcoxon(d, method='approx')\n",
    "    p = results.pvalue\n",
    "    # adapted from https://stats.stackexchange.com/q/133077\n",
    "    r = np.abs(results.zstatistic / np.sqrt(len(d) * 2))\n",
    "    return p, r\n",
    "\n",
    "def style_p_values(fig, brackets, scale=0, _format=dict(interline=0.07, text_height=1.07, color='gray')):\n",
    "    # adapted from https://stackoverflow.com/q/67505252\n",
    "    for entry in brackets:\n",
    "        first_column, second_column, y, results = entry\n",
    "        y_range = [1.01+y*_format['interline'], 1.02+y*_format['interline']]\n",
    "        p, r = results\n",
    "        if p >= 0.05:\n",
    "            symbol = 'ns'\n",
    "        elif p >= 0.01: \n",
    "            symbol = '*'\n",
    "        elif p >= 0.001:\n",
    "            symbol = '**'\n",
    "        else:\n",
    "            symbol = '***'\n",
    "        first_column = first_column - scale\n",
    "        second_column = second_column + scale\n",
    "        fig.add_shape(type=\"line\",\n",
    "            xref=\"x\", yref=\"y domain\",\n",
    "            x0=first_column, y0=y_range[0],\n",
    "            x1=first_column, y1=y_range[1],\n",
    "            line=dict(color=_format['color'], width=2,)\n",
    "        )\n",
    "        fig.add_shape(type=\"line\",\n",
    "            xref=\"x\", yref=\"y domain\",\n",
    "            x0=first_column, y0=y_range[1], \n",
    "            x1=second_column, y1=y_range[1],\n",
    "            line=dict(color=_format['color'], width=2,)\n",
    "        )\n",
    "        fig.add_shape(type=\"line\",\n",
    "            xref=\"x\", yref=\"y domain\",\n",
    "            x0=second_column, y0=y_range[0], \n",
    "            x1=second_column, y1=y_range[1],\n",
    "            line=dict(color=_format['color'], width=2,)\n",
    "        )\n",
    "        fig.add_annotation(dict(font=dict(color=_format['color'],size=14),\n",
    "            x=(first_column + second_column)/2,\n",
    "            y=y_range[1]*_format['text_height'],\n",
    "            showarrow=False,\n",
    "            text=symbol + ' <sup>(' + str(round(r, 2)) + ')</sup>',\n",
    "            textangle=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"y domain\"\n",
    "        ))\n",
    "    return fig\n",
    "\n",
    "def bracket_for(i, j, xshift, y, results):\n",
    "    return [i + xshift, j + xshift, y, results]\n",
    "\n",
    "def filter_extractor(df, extractor):\n",
    "    return df[df['extractor'] == extractor]\n",
    "\n",
    "def annotate_value(fig, x, y, subplot, prefix, ax, ay, xanchor, df, fn=lambda prefix, label: prefix + ': ' + label if label else prefix, label=None, size=None):\n",
    "    if isinstance(x, str):\n",
    "        x = df[x].iat[0]\n",
    "    if isinstance(y, str):\n",
    "        y = log10(df[y].iat[0]/1000000000)\n",
    "    if isinstance(label, str):\n",
    "        label = df[label].iat[0]\n",
    "    else:\n",
    "        label = format(round(y), ',')  if y > 0 else None\n",
    "    fig.add_annotation(\n",
    "        xref='x' + str(subplot),\n",
    "        yref='y' + str(subplot),\n",
    "        x=x,\n",
    "        y=y,\n",
    "        ax=ax,\n",
    "        ay=ay,\n",
    "        xanchor=xanchor,\n",
    "        text=fn(prefix, label),\n",
    "        font=dict(size=size)\n",
    "    )\n",
    "\n",
    "def show(fig, name=None, width=1000, height=500, margin=None, show=True, format='pdf', scale=1):\n",
    "    fig.update_layout(width=width, height=height)\n",
    "    if margin:\n",
    "        fig.update_layout(margin=margin)\n",
    "    else:\n",
    "        fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))\n",
    "    if figures_directory and os.path.isdir(figures_directory) and name:\n",
    "        fig.write_image(f'{figures_directory}/{name}.{format}', scale=scale)\n",
    "    if show:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differentiate kinds of features\n",
    "\n",
    "potential_misses_grep = set()\n",
    "potential_misses_kmax = set()\n",
    "extractor_comparison = {}\n",
    "df_configs_configurable = df_configs.copy()\n",
    "df_configs_configurable['configurable'] = False\n",
    "\n",
    "def jaccard(a, b):\n",
    "    return len(set.intersection(a, b)) / len(set.union(a, b))\n",
    "\n",
    "def add_features(descriptor, source, features, min=2):\n",
    "    descriptor[f'#{source}'] = len(features) if features is not None and len(features) >= min else np.nan\n",
    "\n",
    "def get_variables(variable_map):\n",
    "    variables = set(variable_map.values())\n",
    "    if len(variables) <= 1:\n",
    "        variables = set()\n",
    "    return variables\n",
    "\n",
    "def read_unconstrained_feature_variables(extractor, revision, architecture):\n",
    "    unconstrained_features_filename = f'{output_directory}/unconstrained-features/{extractor}/linux/{revision}[{architecture}].unconstrained.features'\n",
    "    unconstrained_feature_variables = set()\n",
    "    if os.path.isfile(unconstrained_features_filename):\n",
    "        with open(unconstrained_features_filename, 'r') as f:\n",
    "            unconstrained_feature_variables = set([re.sub('^CONFIG_', '', f.strip()) for f in f.readlines()])\n",
    "    return unconstrained_feature_variables\n",
    "\n",
    "def inspect_architecture_features_for_model(extractor, revision, architecture, config_features, features_for_last_revision):\n",
    "    global potential_misses_grep, potential_misses_kmax\n",
    "    \n",
    "    features_filename = f'{output_directory}/kconfig/{extractor}/linux/{revision}[{architecture}].features'\n",
    "    with open(features_filename, 'r') as f:\n",
    "        extracted_features = set([re.sub('^CONFIG_', '', f.strip()) for f in f.readlines()])\n",
    "    \n",
    "    unconstrained_feature_variables = read_unconstrained_feature_variables(extractor, revision, architecture)\n",
    "\n",
    "    dimacs_filename = f'{output_directory}/backbone-dimacs/{extractor}/linux/{revision}[{architecture}].backbone.dimacs'\n",
    "    all_variables = set()\n",
    "    variables = set()\n",
    "    feature_variables = set()\n",
    "    core_feature_variables = set()\n",
    "    dead_feature_variables = set()\n",
    "    undead_feature_variables = set()\n",
    "    all_feature_variables = set()\n",
    "    features = set()\n",
    "    core_features = set()\n",
    "    unconstrained_features = set()\n",
    "    constrained_features = set()\n",
    "    added_features = None\n",
    "    removed_features = None\n",
    "    infos = {'extracted_features_jaccard': np.nan, \\\n",
    "                     'all_variables_jaccard': np.nan, \\\n",
    "                     'variables_jaccard': np.nan, \\\n",
    "                     'feature_variables_jaccard': np.nan, \\\n",
    "                     'undead_feature_variables_jaccard': np.nan, \\\n",
    "                     'all_feature_variables_jaccard': np.nan, \\\n",
    "                     'features_jaccard': np.nan, \\\n",
    "                     'unconstrained_bools': np.nan, \\\n",
    "                     'unconstrained_tristates': np.nan}\n",
    "    \n",
    "    if os.path.isfile(dimacs_filename):\n",
    "        with open(dimacs_filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            all_variable_map = {}\n",
    "            variable_map = {}\n",
    "            feature_variable_map = {}\n",
    "            for f in lines:\n",
    "                if f.startswith('c '):\n",
    "                    result = re.search('^c ([^ ]+) ([^ ]+)$', f)\n",
    "                    if result:\n",
    "                        index = int(result.group(1).strip())\n",
    "                        name = result.group(2).strip()\n",
    "                        all_variable_map[index] = name\n",
    "                        if \"k!\" not in name:\n",
    "                            variable_map[index] = name\n",
    "                            if name != 'True' \\\n",
    "                                and name != '<unsupported>' \\\n",
    "                                and name != 'PREDICATE_Compare' \\\n",
    "                                and not name.startswith('__VISIBILITY__CONFIG_') \\\n",
    "                                and not name.endswith('_MODULE'):\n",
    "                                feature_variable_map[index] = name\n",
    "            all_variables = get_variables(all_variable_map)\n",
    "            variables = get_variables(variable_map)\n",
    "            feature_variables = get_variables(feature_variable_map)\n",
    "\n",
    "            backbone_features_filename = f'{output_directory}/backbone-features/{extractor}/linux/{revision}[{architecture}].backbone.features'\n",
    "            if os.path.isfile(backbone_features_filename):\n",
    "                with open(backbone_features_filename, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    if len(lines) > 1:\n",
    "                        core_feature_variables = set([line[1:].strip() for line in lines if line.startswith('+')]).intersection(feature_variables)\n",
    "                        dead_feature_variables = set([line[1:].strip() for line in lines if line.startswith('-')]).intersection(feature_variables)\n",
    "\n",
    "            if len(feature_variables) > 0:\n",
    "                undead_feature_variables = feature_variables.difference(dead_feature_variables)\n",
    "                all_feature_variables = undead_feature_variables.union(unconstrained_feature_variables)\n",
    "                features = all_feature_variables.intersection(config_features)\n",
    "                if f'{revision}###{architecture}' not in extractor_comparison:\n",
    "                    extractor_comparison[f'{revision}###{architecture}'] = features\n",
    "                else:\n",
    "                    extractor_comparison[f'{revision}###{architecture}'] = jaccard(extractor_comparison[f'{revision}###{architecture}'], features)\n",
    "                core_features = features.intersection(core_feature_variables)\n",
    "                unconstrained_features = features.intersection(unconstrained_feature_variables)\n",
    "                unconstrained_features_by_type = pd.DataFrame(list(unconstrained_features), columns=['config']) \\\n",
    "                    .merge(df_config_types[(df_config_types['revision'] == revision)])\n",
    "                unconstrained_bools = unconstrained_features_by_type[unconstrained_features_by_type['type'] == 'bool']['config'].drop_duplicates()\n",
    "                unconstrained_tristates = unconstrained_features_by_type[unconstrained_features_by_type['type'] == 'tristate']['config'].drop_duplicates()\n",
    "                constrained_features = features.difference(core_feature_variables).difference(unconstrained_feature_variables)\n",
    "                if architecture in features_for_last_revision and len(features_for_last_revision[architecture]) > 0:\n",
    "                    added_features = features.difference(features_for_last_revision[architecture])\n",
    "                    removed_features = features_for_last_revision[architecture].difference(features)\n",
    "                infos = { \\\n",
    "                            'extracted_features_jaccard': jaccard(extracted_features, features), \\\n",
    "                            'all_variables_jaccard': jaccard(all_variables, features), \\\n",
    "                            'variables_jaccard': jaccard(variables, features), \\\n",
    "                            'feature_variables_jaccard': jaccard(feature_variables, features), \\\n",
    "                            'undead_feature_variables_jaccard': jaccard(undead_feature_variables, features), \\\n",
    "                            'all_feature_variables_jaccard': jaccard(all_feature_variables, features), \\\n",
    "                            'features_jaccard': 1, \\\n",
    "                            'unconstrained_bools': len(unconstrained_bools), \\\n",
    "                            'unconstrained_tristates': len(unconstrained_tristates) \\\n",
    "                        }\n",
    "    descriptor = {'extractor': extractor, 'revision': revision, 'architecture': architecture} | infos\n",
    "    add_features(descriptor, 'config_features', config_features) # F_config\n",
    "    add_features(descriptor, 'extracted_features', extracted_features) # F_extracted\n",
    "    add_features(descriptor, 'unconstrained_feature_variables', unconstrained_feature_variables, min=1) # F_unconstrained\n",
    "    add_features(descriptor, 'all_variables', all_variables) # V_all\n",
    "    add_features(descriptor, 'variables', variables) # V_phi\n",
    "    add_features(descriptor, 'feature_variables', feature_variables) # FV_phi\n",
    "    add_features(descriptor, 'core_feature_variables', core_feature_variables, min=1) # FV_core\n",
    "    add_features(descriptor, 'dead_feature_variables', dead_feature_variables, min=1) # FV_dead\n",
    "    add_features(descriptor, 'constrained_feature_variables', undead_feature_variables.difference(core_feature_variables)) # FV_constrained\n",
    "    add_features(descriptor, 'undead_feature_variables', undead_feature_variables) # FV_undead\n",
    "    add_features(descriptor, 'all_feature_variables', all_feature_variables) # FV\n",
    "    add_features(descriptor, 'ALL_feature_variables', feature_variables.union(unconstrained_feature_variables)) # FV_all\n",
    "    add_features(descriptor, 'features', features) # F\n",
    "    add_features(descriptor, 'core_features', core_features, min=1)\n",
    "    add_features(descriptor, 'unconstrained_features', unconstrained_features, min=1)\n",
    "    add_features(descriptor, 'constrained_features', constrained_features)\n",
    "    add_features(descriptor, 'added_features', added_features, min=0)\n",
    "    add_features(descriptor, 'removed_features', removed_features, min=0)\n",
    "    if extractor == 'kmax':\n",
    "        potential_misses_grep.update([f for f in all_feature_variables.difference(features) if '__CONFIG_' not in f])\n",
    "    return descriptor, feature_variables.union(unconstrained_feature_variables), features\n",
    "\n",
    "def inspect_architecture_features_for_revision(extractor, revision, features_for_last_revision):\n",
    "    config_features = set(df_configs[df_configs['revision'] == revision]['config'])\n",
    "    architectures = [re.search('\\[(.*)\\]', f).group(1) for f in glob.glob(f'{output_directory}/kconfig/{extractor}/linux/{revision}[*.features')]\n",
    "    architectures = list(set(architectures))\n",
    "    architectures.sort()\n",
    "    data = []\n",
    "    total_features = set()\n",
    "    total_feature_variables = set()\n",
    "    features_for_current_revision = {}\n",
    "    for architecture in architectures:\n",
    "        descriptor, feature_variables, features = inspect_architecture_features_for_model(extractor, revision, architecture, config_features, features_for_last_revision)\n",
    "        data.append(descriptor)\n",
    "        total_features.update(features)\n",
    "        features_for_current_revision[architecture] = features\n",
    "        if extractor == 'kmax':\n",
    "            total_feature_variables.update(feature_variables)\n",
    "    for descriptor in data:\n",
    "        add_features(descriptor, 'total_features', total_features)\n",
    "        total_added_features = None\n",
    "        total_removed_features = None\n",
    "        if 'TOTAL' in features_for_last_revision and len(features_for_last_revision['TOTAL']) > 0:\n",
    "            total_added_features = total_features.difference(features_for_last_revision['TOTAL'])\n",
    "            total_removed_features = features_for_last_revision['TOTAL'].difference(total_features)\n",
    "        add_features(descriptor, 'total_added_features', total_added_features, min=0)\n",
    "        add_features(descriptor, 'total_removed_features', total_removed_features, min=0)\n",
    "    features_for_current_revision['TOTAL'] = total_features\n",
    "    df_configs_configurable.loc[(df_configs_configurable['revision'] == revision) & (df_configs_configurable['config'].isin(total_features)), 'configurable'] = True\n",
    "    if extractor == 'kmax':\n",
    "        potential_misses_kmax.update([f for f in config_features.difference(total_feature_variables)])\n",
    "    return data, features_for_current_revision\n",
    "\n",
    "def inspect_architecture_features(extractor):\n",
    "    print(f'{extractor} ', end='')\n",
    "    revisions = [re.search('/linux/(.*)\\[', f).group(1) for f in glob.glob(f'{output_directory}/kconfig/{extractor}/linux/*.features')]\n",
    "    revisions = list(set(revisions))\n",
    "    revisions.sort(key=Version)\n",
    "    data = []\n",
    "    features_for_last_revision = {}\n",
    "    i = 0\n",
    "    for revision in revisions:\n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            print(revision + ' . ', end='')\n",
    "        new_data, features_for_last_revision = inspect_architecture_features_for_revision(extractor, revision, features_for_last_revision)\n",
    "        data += new_data\n",
    "    print()\n",
    "    return data\n",
    "\n",
    "if os.path.isfile(f'{output_directory}/linux-features.dat'):\n",
    "    with open(f'{output_directory}/linux-features.dat', 'rb') as f:\n",
    "        [features_by_kind_per_architecture, df_extractor_comparison, potential_misses_grep, potential_misses_kmax, df_configs_configurable] = pickle.load(f)\n",
    "else:\n",
    "    features_by_kind_per_architecture = inspect_architecture_features('kconfigreader')\n",
    "    features_by_kind_per_architecture += inspect_architecture_features('kmax')\n",
    "    features_by_kind_per_architecture = pd.DataFrame(features_by_kind_per_architecture)\n",
    "    df_extractor_comparison = []\n",
    "    for key, value in extractor_comparison.items():\n",
    "        [revision, architecture] = key.split('###')\n",
    "        if type(value) is set:\n",
    "            value = pd.NA\n",
    "        df_extractor_comparison.append({'revision': revision, 'architecture': architecture, 'extractor_jaccard': value})\n",
    "    df_extractor_comparison = pd.DataFrame(df_extractor_comparison)\n",
    "    with open(f'{output_directory}/linux-features.dat', 'wb') as f:\n",
    "        pickle.dump([features_by_kind_per_architecture, df_extractor_comparison, potential_misses_grep, potential_misses_kmax, df_configs_configurable], f)\n",
    "\n",
    "replace_values(features_by_kind_per_architecture)\n",
    "df_features = pd.merge(df_architectures, features_by_kind_per_architecture, how='outer').sort_values(by='committer_date')\n",
    "df_features = pd.merge(df_kconfig, df_features, how='outer').sort_values(by='committer_date')\n",
    "\n",
    "def compare_with_grep(message, list):\n",
    "    print(f'{message}: ' + str(len(list)))\n",
    "    print(pd.merge(df_configs[['config','kconfig-file']], pd.DataFrame(list, columns=['config']), how='inner') \\\n",
    "        .drop_duplicates().merge(df_config_types[['config', 'type']]).drop_duplicates())\n",
    "\n",
    "def report_potential_misses(potential_misses_grep, potential_misses_kmax):\n",
    "    # these are the features NOT found by grep, but found by kmax (this allows us to check whether the grep regex matches too much)\n",
    "    # the only matches are enviroment variables (e.g., ARCH) and mistakes in kconfig files: IA64_SGI_UV (which has a trailing `) and SND_SOC_UX500_MACH_MOP500 (which has a leading +)\n",
    "    compare_with_grep('#potential misses (grep)', potential_misses_grep)\n",
    "    print()\n",
    "\n",
    "    # these are the features found by grep, but NOT found by kmax, either constrained or unconstrained (this allows us to check whether kmax matches enough)\n",
    "    # as there are some extraction failures for kmax, we expect some misses; also, we do not extract the um architecture; and finally, there are some test kconfig files that are never included\n",
    "    # in the following, we try to filter out these effects (this is not perfect though)\n",
    "    potential_misses_kmax_with_type = (pd.merge(df_configs[['config','kconfig-file', 'revision']], pd.DataFrame(potential_misses_kmax, columns=['config']), how='inner') \\\n",
    "            .drop_duplicates().merge(df_config_types[['config', 'type']]).drop_duplicates())\n",
    "    misses_due_to_tests = set(potential_misses_kmax_with_type[ \\\n",
    "            potential_misses_kmax_with_type['kconfig-file'].str.startswith('Documentation/') | \\\n",
    "            potential_misses_kmax_with_type['kconfig-file'].str.startswith('scripts/')]['config'].unique())\n",
    "    missing_kmax_models = df_features[(df_features['extractor'] == 'KClause') & df_features['#extracted_features'].isna()]\n",
    "    missing_kmax_models = missing_kmax_models[['revision', 'architecture']].drop_duplicates()\n",
    "    potential_misses_kmax_with_type['architecture'] = potential_misses_kmax_with_type['kconfig-file'].apply(lambda s: re.sub(r'^arch/(.*?)/.*$', r'\\1', s))\n",
    "    potential_misses_due_to_missing_kmax_models = set(potential_misses_kmax_with_type.merge(missing_kmax_models[['revision', 'architecture']].drop_duplicates()) \\\n",
    "                                                    .drop(columns=['kconfig-file', 'revision', 'architecture', 'type'])['config'].unique())\n",
    "    potential_misses_kmax = potential_misses_kmax.difference(misses_due_to_tests).difference(potential_misses_due_to_missing_kmax_models)\n",
    "    # the remaining matches are due to our way of using kmax extractor, where we ignore lines with new kconfig constructs like $(success,...)\n",
    "    compare_with_grep('#potential misses (kmax)', potential_misses_kmax)\n",
    "\n",
    "report_potential_misses(potential_misses_grep, potential_misses_kmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "df_total_features = df_features.groupby(['extractor', 'revision']).agg({'#total_features': 'min'}).reset_index()\n",
    "df_total_features = pd.merge(df_kconfig[['committer_date', 'revision']].drop_duplicates(), df_total_features)\n",
    "df_total_features = df_total_features[df_total_features['extractor']=='KClause']\n",
    "df = df_total_features.sort_values(by='committer_date')\n",
    "df = df[['committer_date', '#total_features']].drop_duplicates()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['committer_date'], y=df['#total_features'], mode='markers', name='Number of Features (r=.99)', marker_symbol='circle'),\n",
    "    secondary_y=False\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_kconfig['committer_date'], y=df_kconfig['source_lines_of_code'], mode='markers', name='Source Lines of Code (r=.98)', marker_symbol='circle'),\n",
    "    secondary_y=True\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Year\")\n",
    "fig.update_yaxes(title_text=\"Number of Features\", dtick=5000, range=[0, 22000], color=\"#648FFF\", title_font_color=\"black\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Source Lines of Code\", dtick=10000000, range=[0, 32000000], color=\"#FE6100\", title_font_color=\"black\", secondary_y=True)\n",
    "\n",
    "style_scatter(fig, marker_size=3, legend_position='topleft')\n",
    "fig.update_xaxes(range=[\"2002-01-01\", \"2025-01-01\"])\n",
    "show(fig, 'sloc', width=400, height=260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics in section 1\n",
    "\n",
    "# show(px.scatter(\n",
    "#     df_kconfig,\n",
    "#     x='committer_date',\n",
    "#     y='source_lines_of_code',\n",
    "#     trendline='ols'\n",
    "# ))\n",
    "\n",
    "# show(px.scatter(\n",
    "#     df,\n",
    "#     x='committer_date',\n",
    "#     y='#total_features',\n",
    "#     trendline='ols'\n",
    "# ))\n",
    "\n",
    "# linear regression of source lines of code and number of features\n",
    "print(scipy.stats.pearsonr(df_kconfig['committer_date'].astype(int) // 10 ** 9, df_kconfig['source_lines_of_code']))\n",
    "print(scipy.stats.pearsonr(df['committer_date'].astype(int) // 10 ** 9, df['#total_features']))\n",
    "print(scipy.stats.linregress(df_kconfig['committer_date'].astype(int) // 10 ** 9, df_kconfig['source_lines_of_code']))\n",
    "print(scipy.stats.linregress(df['committer_date'].astype(int) // 10 ** 9, df['#total_features']))\n",
    "\n",
    "# lines of code per year\n",
    "print(0.032409366566693104*60*60*24*365.25)\n",
    "# features per year\n",
    "print(2.6766885381596744e-05*60*60*24*365.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(d):\n",
    "    try:\n",
    "        return 2000 + int(d.split('-')[0])\n",
    "    except:\n",
    "        if d == 'IsaSAT' or d == 'MergeSat':\n",
    "            return 2023\n",
    "        return int(d.split('-')[-1])\n",
    "\n",
    "def scope_to(df, source_descriptor):\n",
    "    if 'extra' not in source_descriptor:\n",
    "        df = df[df['source-analyzer']!='extra']\n",
    "    if 'extra' in source_descriptor and not source_descriptor.endswith('+timeout'):\n",
    "        # most timeouts are caused by the stochastic local search solvers (SLS) unitwalk and adaptg2wsat2011 on unsatisfiable instances (see below)\n",
    "        # these solvers are not able to solve/prove unsatisfiable instances, so it is unfair to include them in the comparison\n",
    "        # thus, we exclude their timeouts here, as the results are necessarily confounded by the number of unsatisfiable queries in the sample\n",
    "        df = df[~df['model-satisfiable'].isna()|(~df['dimacs-analyzer'].str.contains('unitwalk')&~df['dimacs-analyzer'].str.contains('adaptg2wsat2011'))]\n",
    "    if source_descriptor.endswith('+timeout'):\n",
    "        source_descriptor = source_descriptor[:-len('+timeout')]\n",
    "    if source_descriptor.endswith('==2024'):\n",
    "        df = df[df['year-analyzer']==2024]\n",
    "        source_descriptor = source_descriptor[:-len('==2024')]\n",
    "    if source_descriptor.endswith('!=2024'):\n",
    "        df = df[df['year-analyzer']!=2024]\n",
    "        source_descriptor = source_descriptor[:-len('!=2024')]\n",
    "    if source_descriptor.endswith('==2023'):\n",
    "        df = df[df['year-analyzer']==2023]\n",
    "        source_descriptor = source_descriptor[:-len('==2023')]\n",
    "    if source_descriptor.endswith('!=2023'):\n",
    "        df = df[df['year-analyzer']!=2023]\n",
    "        source_descriptor = source_descriptor[:-len('!=2023')]\n",
    "    if len(source_descriptor) > 0:\n",
    "        if source_descriptor == 'sat-museum+competition':\n",
    "            return df[(df['source-analyzer']=='sat-museum')|((df['source-analyzer']=='sat-competition')&(df['year-analyzer']>=2023))]\n",
    "        df = df[df['source-analyzer']==source_descriptor]\n",
    "    return df\n",
    "\n",
    "pd.set_option('mode.copy_on_write', True)\n",
    "output_directory = '../../output-archive/output-fin-2025-06-19'\n",
    "df2_sat = read_dataframe(f'solve_model-satisfiable')\n",
    "df2_dimacs = read_dataframe(f'dimacs')\n",
    "output_directory = '../../output-archive/stages-time-travel-2025-11-02'\n",
    "df2_sat_extra = read_dataframe(f'solve_sat')\n",
    "df2_solver_loc = read_dataframe(f'solver_loc')\n",
    "df2_dimacs['year'] = df2_dimacs['committer_date'].apply(lambda d: int(d.year))\n",
    "for df in [df2_sat, df2_sat_extra, df2_dimacs]:\n",
    "    replace_values(df)\n",
    "    df.replace('i386', 'x86', inplace=True)\n",
    "    df.replace('model_to_dimacs_kconfigreader', 'KConfigReader', inplace=True)\n",
    "    df.replace('smt_to_dimacs_z3', 'Z3', inplace=True)\n",
    "    df.replace('sat-competition/', '', inplace=True, regex=True)\n",
    "    df.replace('/home/input/sat_heritage/sat-heritage/run', '', inplace=True, regex=True)\n",
    "    df.replace('other/', '', inplace=True, regex=True)\n",
    "    df.replace('.sh', '', inplace=True, regex=True)\n",
    "    df.replace('SAT4J.210', '09-Sat4j 2.1.0', inplace=True, regex=True)\n",
    "    df.replace('SAT4J.231', '11-Sat4j 2.3.1', inplace=True, regex=True)\n",
    "    df.replace('SAT4J.235', '14-Sat4j 2.3.5', inplace=True, regex=True)\n",
    "df2_sat['query'] = 'void'\n",
    "df2_sat_extra = df2_sat_extra.rename(columns={'dimacs_file': 'dimacs-file', 'dimacs_query': 'query', 'dimacs_solver': 'dimacs-analyzer', 'dimacs_solver_time': 'dimacs-analyzer-time', 'sat': 'model-satisfiable'})\n",
    "df2_sat_extra['dimacs-file'] = 'smt_to_dimacs_z3/kmax/1/' + df2_sat_extra['dimacs-file'].astype(str)\n",
    "df2_sat_extra['iteration'] = 1\n",
    "df2_sat_extra['dimacs-analyzer'] = df2_sat_extra['dimacs-analyzer'].str.strip()\n",
    "df2_sat['year-analyzer'] = df2_sat['dimacs-analyzer'].apply(get_year)\n",
    "df2_sat_extra['year-analyzer'] = df2_sat_extra['dimacs-analyzer'].apply(get_year)\n",
    "df2_sat['source-analyzer'] = df2_sat['dimacs-analyzer'].str.split('-', expand=True)[0].str.isdigit().map({True: 'sat-competition', False: 'sat-museum'})\n",
    "df2_sat_extra['source-analyzer'] = 'extra'\n",
    "df2_sat.loc[df2_sat['dimacs-analyzer'].str.contains('Sat4j'), 'source-analyzer'] = 'FeatureIDE'\n",
    "df2_sat = pd.concat([df2_sat, df2_sat_extra])\n",
    "df2=df2_sat.merge(df2_dimacs).merge(df_features, on=['model-file'], how='left', suffixes=(None, '_2'))\n",
    "df2_solver_loc.rename(columns={'dimacs_solver': 'dimacs-analyzer', 'source_lines_of_code': 'solver_source_lines_of_code', 'source_lines_of_code_extended': 'solver_source_lines_of_code_extended', 'language': 'solver_language'}, inplace=True)\n",
    "df2_solver_loc['solver_source_lines_of_code_extended'] = df2_solver_loc['solver_source_lines_of_code_extended'].fillna(df2_solver_loc['solver_source_lines_of_code'])\n",
    "df2=df2.merge(df2_solver_loc.rename(columns={'dimacs_solver': 'dimacs-analyzer'}), on=['dimacs-analyzer'], how='left')\n",
    "pd.set_option('mode.copy_on_write', False)\n",
    "print('unexpectedly unsatisfiable instances: ' + str(len(df2[(df2['model-satisfiable']==False)&(df2['query']=='void')])))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we determine whether there is a noticeable influence of iterations in our experiment\n",
    "# there isn't for all solvers except 24-kissat-sc2024, so in the following we only plot median values\n",
    "\n",
    "df_iterations = []\n",
    "# for source in ['==2024', 'sat-competition!=2024', 'sat-museum', 'FeatureIDE']:\n",
    "for source in ['==2024', '!=2024']:\n",
    "    pd.set_option('mode.copy_on_write', True)\n",
    "    df_tmp = scope_to(df2.copy(), source)\n",
    "    # df_tmp = df_tmp[df_tmp['model-file'].str.startswith('kconfigreader/1')|df_tmp['model-file'].str.startswith('kmax/1')] # both extractors significantly affect kissat\n",
    "    # df_tmp = df_tmp[df_tmp['dimacs-file'].str.startswith('model_to_dimacs_kconfigreader/1')] # the KConfigReader transformation significantly affects kissat\n",
    "    df_tmp['dimacs-analyzer-time-normalized'] = df_tmp[['year', 'revision', 'architecture', 'extractor', 'dimacs-transformer', 'dimacs-analyzer', 'dimacs-analyzer-time']].groupby(['year', 'revision', 'architecture', 'extractor', 'dimacs-transformer', 'dimacs-analyzer']).transform(lambda x: (x / x.median()))\n",
    "    df_tmp['dimacs-analyzer-time-z-score'] = df_tmp[['year', 'revision', 'architecture', 'extractor', 'dimacs-transformer', 'dimacs-analyzer', 'dimacs-analyzer-time']].groupby(['year', 'revision', 'architecture', 'extractor', 'dimacs-transformer', 'dimacs-analyzer']).transform(lambda x: (x - x.mean()) / x.std())\n",
    "    df_tmp['iteration-source'] = source\n",
    "    df_iterations.append(df_tmp)\n",
    "    pd.set_option('mode.copy_on_write', False)\n",
    "df_iterations = pd.concat(df_iterations)\n",
    "\n",
    "# for y in ['dimacs-analyzer-time-normalized', 'dimacs-analyzer-time-z-score']:\n",
    "for y in ['dimacs-analyzer-time-normalized']:\n",
    "    fig = px.box(\n",
    "    # fig = px.violin(\n",
    "        df_iterations,\n",
    "        # points=False,\n",
    "        # x=df_tmp['year-analyzer'],\n",
    "        facet_col='iteration-source',\n",
    "        color='iteration-source',\n",
    "        y=df_iterations[y],\n",
    "        # Rel. Dev. Median SAT Runtime\n",
    "        labels={'dimacs-analyzer-time-normalized': 'Relative Deviation (log<sub>10</sub>)', 'dimacs-analyzer-time-z-score': 'z-Score For SAT Solving Time', 'architecture': 'Architecture', 'dimacs-analyzer': 'SAT Solver'},\n",
    "        category_orders={'iteration-source': ['==2024', '!=2024']},\n",
    "        hover_data=['revision', 'dimacs-analyzer', 'architecture', 'dimacs-transformer', 'extractor'],\n",
    "        log_y=True,\n",
    "        # points=False\n",
    "    )\n",
    "    fig.update_layout(boxmode='group', boxgap=0.2)\n",
    "    fig.update_traces(width=0.02)\n",
    "    style_box(fig, legend_position=None)\n",
    "    show(fig, 'factor-iteration', width=100, height=0.6*default_height, format='png', scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in ['architecture', 'extractor', 'dimacs-transformer', 'source-analyzer']:\n",
    "    print(factor)\n",
    "    df_factor = scope_to(df2, '')\n",
    "    if factor == 'architecture':\n",
    "        category_orders = ['x86', 'arm']\n",
    "    elif factor == 'extractor':\n",
    "        category_orders = ['KConfigReader', 'KClause']\n",
    "    elif factor == 'dimacs-transformer':\n",
    "        category_orders = ['KConfigReader', 'Z3']\n",
    "    elif factor == 'source-analyzer':\n",
    "        category_orders = ['sat-competition', 'sat-museum']\n",
    "        # does the gcc compiler version significantly affect results?\n",
    "        df_factor = df_factor[(df_factor['source-analyzer']=='sat-competition') | (df_factor['source-analyzer']=='sat-museum')]\n",
    "        # 2002 and 2003 are different solvers in both datasets\n",
    "        # 2023 and 2024 are not included in the museum dataset\n",
    "        df_factor = df_factor[(df_factor['year-analyzer']!=2002)&(df_factor['year-analyzer']!=2003)&(df_factor['year-analyzer']!=2023)&(df_factor['year-analyzer']!=2024)]\n",
    "\n",
    "    fig = px.box(\n",
    "        df_factor,\n",
    "        y=df_factor['dimacs-analyzer-time'] / 1000000000,\n",
    "        facet_col=factor,\n",
    "        color=factor,\n",
    "        log_y=True,\n",
    "        category_orders={factor: category_orders},\n",
    "        labels={'y': 'SAT Runtime (log<sub>10</sub> s)'},\n",
    "        boxmode='group',\n",
    "        # points=False\n",
    "    )\n",
    "    fig.update_layout(boxmode='group', boxgap=0.2)\n",
    "    fig.update_traces(width=0.02)\n",
    "    style_box(fig, legend_position=None)\n",
    "    show(fig, f'factor-{factor}', width=80, height=0.6*default_height, margin=dict(l=40, r=0, t=0, b=0), format='png', scale=4)\n",
    "    # print(scipy.stats.ttest_ind(*df_factor.groupby(factor)['dimacs-analyzer-time'].apply(lambda x:x.values)))\n",
    "    # print(cohens_d(*df_factor.groupby(factor)['dimacs-analyzer-time'].apply(lambda x:x.values)))\n",
    "    print(scipy.stats.mannwhitneyu(*df_factor.groupby(factor)['dimacs-analyzer-time'].apply(lambda x:x.values)))\n",
    "    print(effect_size_mannwhitneyu(*df_factor.groupby(factor)['dimacs-analyzer-time'].apply(lambda x:x.values)))\n",
    "    if factor == 'dimacs-transformer':\n",
    "        df_factor_dimacs_transformer = []\n",
    "        fig = px.box(df_factor.replace({'KConfigReader': 'KCR'}), x='dimacs-transformer', color='dimacs-transformer', y=df_factor['dimacs-analyzer-time'] / 1000000000, facet_col='year-analyzer', log_y=True, labels={'dimacs-transformer': '', 'source-analyzer': ''})\n",
    "        # show(fig, width=4*330, height=default_height)\n",
    "        for extractor in df_factor['extractor'].unique():\n",
    "            for solver in df_factor['dimacs-analyzer'].unique():\n",
    "                df_factor_dimacs_transformer.append({'extractor': extractor, 'dimacs-analyzer': solver, 'significant': scipy.stats.mannwhitneyu(*df_factor[(df_factor['dimacs-analyzer']==solver)&(df_factor['extractor']==extractor)].groupby(factor)['dimacs-analyzer-time'].apply(lambda x:x.values)).pvalue < 0.005, 'effect_size': effect_size_mannwhitneyu(*df_factor[(df_factor['dimacs-analyzer']==solver)&(df_factor['extractor']==extractor)].groupby(factor)['dimacs-analyzer-time'].apply(lambda x:x.values))})\n",
    "        for extractor in df_factor['extractor'].unique():\n",
    "            if scipy.stats.mannwhitneyu(*df_factor[(df_factor['extractor']==extractor)].groupby(factor)['dimacs-analyzer-time'].apply(lambda x:x.values)).pvalue < 0.005:\n",
    "                print(str(extractor) + 'u: ' + str(effect_size_mannwhitneyu(*df_factor[(df_factor['extractor']==extractor)].groupby(factor)['dimacs-analyzer-time'].apply(lambda x:x.values))))\n",
    "        df_factor_dimacs_transformer = pd.DataFrame(df_factor_dimacs_transformer)\n",
    "    if factor == 'source-analyzer':\n",
    "        fig = px.box(df_factor, x='source-analyzer', color='source-analyzer', y=df_factor['dimacs-analyzer-time'] / 1000000000, facet_col='year-analyzer', log_y=True, labels={'dimacs-transformer': '', 'source-analyzer': ''})\n",
    "        \n",
    "        # show(fig, width=4*330, height=default_height)\n",
    "        # the solvers differ and are not comparable in 2002 and 2003, so we omit them here\n",
    "        for year in range(2004, 2023):\n",
    "            # if scipy.stats.ttest_ind(*df_factor[(df_factor['year-analyzer']==year)].groupby('source-analyzer')['dimacs-analyzer-time'].apply(lambda x:x.values)).pvalue < 0.005:\n",
    "            #     print(str(year) + ' t: ' + str(cohens_d(*df_factor[(df_factor['year-analyzer']==year)].groupby('source-analyzer')['dimacs-analyzer-time'].apply(lambda x:x.values))))\n",
    "            if scipy.stats.mannwhitneyu(*df_factor[(df_factor['year-analyzer']==year)].groupby('source-analyzer')['dimacs-analyzer-time'].apply(lambda x:x.values)).pvalue < 0.005:\n",
    "                print(str(year) + 'u: ' + str(effect_size_mannwhitneyu(*df_factor[(df_factor['year-analyzer']==year)].groupby('source-analyzer')['dimacs-analyzer-time'].apply(lambda x:x.values))))\n",
    "    print('variance comparison:')\n",
    "    variance = df_factor.groupby(factor)['dimacs-analyzer-time'].var()\n",
    "    print(variance)\n",
    "    print((variance.iloc[0]/variance.iloc[1])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the median of the entire experiment, CNF transformation has a negligible effect\n",
    "# however, for many specific extractor-solver combinations, there is a significant (p<.005) effect\n",
    "# here we plot the effect sizes as a histogram to check whether it matters which extractor or solver we consider\n",
    "# the result shows that KConfigReader extraction pairs well with Z3 CNF transformation (and, surprisingly, not well with its own integrated CNF transformation)\n",
    "# and KClause extraction pairs well with KConfigReader CNF transformation (not with Z3, as is done all throughout the KMax tooling)\n",
    "# the solvers themselves matter much less than the extractor\n",
    "# this is a new and counterintuitive result, and it remains to be seen whether this holds on other systems than Linux\n",
    "df_current = df_factor_dimacs_transformer[df_factor_dimacs_transformer['significant']]\n",
    "bin_width = 0.05 # adjust as needed\n",
    "max_val = np.ceil(np.max(np.abs(df_current['effect_size'])) / bin_width) * bin_width\n",
    "start = -max_val - bin_width / 2\n",
    "end = max_val + bin_width / 2\n",
    "fig=px.histogram(df_current, x='effect_size', labels={'effect_size': 'Effect Size (Mann-Whitney U)'}, color='extractor')\n",
    "fig.update_traces(xbins=dict(start=start, end=end, size=bin_width))\n",
    "fig.update_layout(yaxis_title_text='#Extractor+Solver')\n",
    "show(fig, width=400, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, x, legend_position=None, facet_col=None, facet_row=None, color=None, color_discrete_sequence=None, xshift=0, yshift=0, color_value=None, agg='median', remove_architecture=True, extractor_label='Extractor', extractor_labels=['KConfigReader', 'KClause'], architecture_label='Architecture', architecture_labels=['x86', 'arm']):\n",
    "    df_tmp = df.copy()\n",
    "    # remove iterations, which almost always have negligible influence\n",
    "    df_tmp = df_tmp.groupby(['year', 'year-analyzer', 'committer_date', 'revision', 'architecture', 'extractor', 'dimacs-transformer', 'dimacs-analyzer', 'source-analyzer']).agg({'dimacs-analyzer-time': agg}).reset_index()\n",
    "    # remove second architecture, which it does not differ significantly\n",
    "    if remove_architecture:\n",
    "        df_tmp = df_tmp[df_tmp['architecture'] == 'x86']\n",
    "    # create additional, optional column for easier plotting\n",
    "    df_tmp['facet'] = df_tmp['extractor'] + ', ' + df_tmp['dimacs-transformer']\n",
    "\n",
    "    df_stats = None\n",
    "    if x == 'committer_date':\n",
    "        fig_ols = px.scatter(\n",
    "            df_tmp,\n",
    "            x=df_tmp[x],\n",
    "            y=df_tmp['dimacs-analyzer-time'] / 1000000000,\n",
    "            facet_col=facet_col,\n",
    "            facet_row=facet_row,\n",
    "            color=color,\n",
    "            symbol='architecture',\n",
    "            log_y=True,\n",
    "            trendline='ols',\n",
    "            trendline_options=dict(log_y=True)\n",
    "        )\n",
    "        results = px.get_trendline_results(fig_ols)\n",
    "        df_stats = []\n",
    "        for i, r in enumerate(results.iloc):\n",
    "            color_value = r[color] if color is not None else None\n",
    "            facet_col_value = r[facet_col] if facet_col is not None else None\n",
    "            facet_row_value = r[facet_row] if facet_row is not None else None\n",
    "            symbol_value = r['architecture']\n",
    "            slope = results.iloc[i]['px_fit_results'].params[1]\n",
    "            yearly = (10**(slope * pd.to_timedelta(1, unit='D').total_seconds() * 365.25))-1\n",
    "            df_row = df_tmp\n",
    "            if color_value is not None:\n",
    "                df_row = df_row[df_row[color] == color_value]\n",
    "            if facet_col_value is not None:\n",
    "                df_row = df_row[df_row[facet_col] == facet_col_value]\n",
    "            if facet_row_value is not None:\n",
    "                df_row = df_row[df_row[facet_row] == facet_row_value]\n",
    "            if symbol_value is not None:\n",
    "                df_row = df_row[df_row['architecture'] == symbol_value]\n",
    "            s = scipy.stats.pearsonr(df_row[x].astype(int) // 10 ** 9, np.log10(df_row['dimacs-analyzer-time'] / 1000000000))\n",
    "            # print(f'{color_value} {facet_col_value} {facet_row_value} {symbol_value}: {yearly:.2%} {s.statistic:.2f} {s.pvalue:.2f}')\n",
    "            df_stats.append({'yearly': yearly, 'r': s.statistic, 'p': s.pvalue, 'color': color_value, 'facet_col': facet_col_value, 'facet_row': facet_row_value, 'symbol': symbol_value})\n",
    "        df_stats = pd.DataFrame(df_stats)\n",
    "\n",
    "    fig = px.line(\n",
    "        df_tmp,\n",
    "        x=df_tmp[x],\n",
    "        y=df_tmp['dimacs-analyzer-time'] / 1000000000,\n",
    "        labels={\n",
    "            'y': 'SAT Runtime (log<sub>10</sub> s)',\n",
    "            'facet': 'Extractor, Transformation',\n",
    "            'dimacs-analyzer': 'SAT Solver',\n",
    "            'architecture': architecture_label,\n",
    "            'extractor': extractor_label,\n",
    "            'dimacs-transformer': 'Transformation',\n",
    "            'year-analyzer': 'Year of SAT Solver',\n",
    "            'committer_date': 'Year of Feature Model',\n",
    "            'revision': 'Revision'\n",
    "        },\n",
    "        hover_data=['revision', 'dimacs-analyzer'],\n",
    "        facet_col=facet_col,\n",
    "        facet_row=facet_row,\n",
    "        color=color,\n",
    "        symbol='architecture',\n",
    "        line_dash='architecture',\n",
    "        symbol_sequence=['circle', 'circle-open'],\n",
    "        line_dash_sequence=['solid', 'dot'],\n",
    "        category_orders={\n",
    "            'extractor': extractor_labels,\n",
    "            'dimacs-transformer': ['KConfigReader', 'Z3'],\n",
    "            'architecture': architecture_labels,\n",
    "            'facet': ['KConfigReader, KConfigReader', 'KConfigReader, Z3', 'KClause, KConfigReader', 'KClause, Z3'],\n",
    "        },\n",
    "        color_discrete_sequence=color_discrete_sequence,\n",
    "        log_y=True,\n",
    "        markers=True\n",
    "    )\n",
    "\n",
    "    fig.update_traces(line_width=1)\n",
    "    style_scatter(fig, legend_position=legend_position)\n",
    "    return fig, df_stats\n",
    "\n",
    "def generate_gradient():\n",
    "    gradient = []\n",
    "    n=8\n",
    "    for i in range(n):\n",
    "        value = int(255 * (((n+1) - i) / (n+1)))\n",
    "        value = int(255 * (i / (n+1)))\n",
    "        color = f'#{value:02x}{value:02x}{value:02x}'\n",
    "        gradient.append(color)\n",
    "    n=10\n",
    "    for i in range(n):\n",
    "        value = int(255 * (((n+1) - i) / (n+1)))\n",
    "        value = int(255 * (i / (n+1)))\n",
    "        color = f'#00{value:02x}ff'\n",
    "        gradient.append(color)\n",
    "    n=5\n",
    "    for i in range(n):\n",
    "        value = int(255 * (((n+1) - i) / (n+1)))\n",
    "        value = int(255 * (i / (n+1)))\n",
    "        # blue_value = int(255 * (1 - (i / n)))\n",
    "        # red_value = int(255 * (i / n))\n",
    "        color = f'#ff{value:02x}00'\n",
    "        gradient.append(color)\n",
    "    return gradient\n",
    "\n",
    "def lreplace(pattern, sub, string):\n",
    "    return re.sub('^%s' % pattern, sub, string)\n",
    "\n",
    "def stats_table(df_stats, group_attributes=['color']):\n",
    "    f = lambda x: lreplace('0\\\\.', '.', x.replace('_', '\\\\_').replace('%', '\\\\%'))\n",
    "    pf = lambda x: f(f'{x:.3f}')\n",
    "    rf = lambda x: f(f'{x:.2f}')\n",
    "    yf = lambda x: f(f'{x:.1%}')\n",
    "    df = df_stats.copy()\n",
    "    df = df.assign(noop='')\n",
    "    if group_attributes is None:\n",
    "        group_attributes = ['noop']\n",
    "    df = df.groupby(group_attributes).agg({'p': ['min', 'median', 'max'], 'r': ['min', 'median', 'max'], 'yearly': ['min', 'median', 'max']}).reset_index()\n",
    "    latex_table = df.to_latex(index=False, formatters=[f, pf, pf, pf, rf, rf, rf, yf, yf, yf])\n",
    "    print(latex_table)\n",
    "\n",
    "def annotate_solvers(fig, df, ay=-15):\n",
    "    fn1 = lambda prefix, label: \"'\" + str(label)[2:4]\n",
    "    last_index = None\n",
    "    last_value = None\n",
    "    for idx, revision in enumerate(df['revision'].unique()):\n",
    "        df_tmp = df[df['revision'] == revision]\n",
    "        current_value = df_tmp['year-analyzer'].iat[0]\n",
    "        height = 1 if idx % 2 == 0 or last_index < idx - 1 else 1.8\n",
    "        if current_value != last_value:\n",
    "            annotate_value(fig, 'committer_date', 'dimacs-analyzer-time', 1, '', 0, ay*height, 'center', df_tmp, fn1, 'year-analyzer', 10)\n",
    "            last_index = idx\n",
    "        last_value = current_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = scope_to(df2, 'sat-museum+competition')\n",
    "fig, df_stats = plot(df_current, x='committer_date', facet_col='extractor', facet_row='dimacs-transformer', color='dimacs-analyzer', color_discrete_sequence=generate_gradient(), legend_position='right', remove_architecture=False)\n",
    "show(fig, width=1500, height=2*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "fig, _ = plot(df_current, x='committer_date', facet_col='extractor', facet_row='dimacs-transformer', color='dimacs-analyzer', color_discrete_sequence=generate_gradient())\n",
    "show(fig, 'sat', width=450, height=1.2*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "# print(scipy.stats.pearsonr(df2['committer_date'].astype(int) // 10 ** 9, df2['source_lines_of_code']))\n",
    "# px.box(\n",
    "#     df2,\n",
    "#     x=df2['committer_date'],\n",
    "#     y=df2['dimacs-analyzer-time'] / 1000000000,\n",
    "#     facet_col='extractor',\n",
    "#     facet_row='dimacs-transformer',\n",
    "#     log_y=True\n",
    "# )\n",
    "stats_table(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = scope_to(df2, 'sat-competition')\n",
    "fig, df_stats = plot(df_current, x='committer_date', facet_col='extractor', facet_row='dimacs-transformer', color='dimacs-analyzer', color_discrete_sequence=generate_gradient(), legend_position='right', remove_architecture=False)\n",
    "show(fig, width=1500, height=2*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "df_current = scope_to(df2, 'sat-museum')\n",
    "fig, df_stats = plot(df_current, x='committer_date', facet_col='extractor', facet_row='dimacs-transformer', color='dimacs-analyzer', color_discrete_sequence=generate_gradient(), legend_position='right', remove_architecture=False)\n",
    "show(fig, width=1500, height=2*default_height, margin=dict(l=0, r=0, t=20, b=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = scope_to(df2, 'sat-museum+competition')\n",
    "fig, _ = plot(df_current[df_current['year-analyzer']==2024], x='committer_date', color='facet', agg='max')\n",
    "show(fig, width=250, height=0.7*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "fig, _ = plot(df_current[df_current['year-analyzer']==2024], x='committer_date', color='facet', agg='min')\n",
    "show(fig, width=250, height=0.7*default_height, margin=dict(l=0, r=0, t=20, b=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = scope_to(df2, 'sat-museum+competition')\n",
    "fig, _ = plot(df_current, x='year-analyzer', facet_col='extractor', facet_row='dimacs-transformer', color='year', color_discrete_sequence=generate_gradient(), legend_position='right', remove_architecture=False)\n",
    "show(fig, width=1500, height=2*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "fig, _ = plot(df_current, x='year-analyzer', facet_col='extractor', facet_row='dimacs-transformer', color='year', color_discrete_sequence=generate_gradient())\n",
    "# fig.add_vrect(x0=\"2002.5\", x1=\"2003.6\", annotation_text=\"'03\", annotation_position=\"top left\", annotation_textangle=-90, fillcolor=\"gray\", opacity=0.1, line_width=0)\n",
    "# fig.add_vrect(x0=\"2022.5\", x1=\"2023.6\", annotation_text=\"'23\", annotation_position=\"top left\", annotation_textangle=-90, fillcolor=\"gray\", opacity=0.1, line_width=0)\n",
    "# fig.add_vrect(x0=\"2023.5\", x1=\"2024.6\", annotation_text=\"'24\", annotation_position=\"top left\", annotation_textangle=-90, fillcolor=\"gray\", opacity=0.1, line_width=0)\n",
    "show(fig, 'fm', width=460, height=1.2*default_height, margin=dict(l=0, r=10, t=20, b=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = scope_to(df2, 'sat-museum+competition')\n",
    "fig, df_stats = plot(df_current[df_current['year-analyzer'] == df_current['year']], x='committer_date', color='facet', legend_position='right', remove_architecture=False)\n",
    "show(fig, width=700, height=default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "df_current = df_current[df_current['year-analyzer'] == df_current['year']]\n",
    "fig, _ = plot(df_current, x='committer_date', color='facet')\n",
    "fig.update_yaxes(range=[-2.1, 2.6])\n",
    "show(fig, 'equals', width=250, height=0.7*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "stats_table(df_stats, None)\n",
    "# fig, _ = plot(df_current[df_current['architecture']=='x86'], x='committer_date', color='facet', legend_position='horizontal')\n",
    "# show(fig, 'legend', width=1500, height=default_height, margin=dict(l=0, r=0, t=20, b=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = scope_to(df2, 'sat-museum+competition')\n",
    "df3 = df_current[df_current['year-analyzer'] <= df_current['year']]\n",
    "df3 = df3.loc[df3.groupby(['year', 'committer_date', 'revision', 'architecture', 'extractor', 'dimacs-transformer'])['dimacs-analyzer-time'].idxmin()]\n",
    "fig, df_stats = plot(df3, x='committer_date', color='facet', legend_position='right', remove_architecture=False)\n",
    "show(fig, width=700, height=default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "fig, _ = plot(df3, x='committer_date', color='facet')\n",
    "fig.update_yaxes(range=[-2.1, 2.6])\n",
    "annotate_solvers(fig, df3[(df3['architecture'] == 'x86')&(df3['extractor'] == 'KConfigReader')&(df3['dimacs-transformer'] == 'KConfigReader')])\n",
    "show(fig, 'lessthan', width=250, height=0.7*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "stats_table(df_stats, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = scope_to(df2, 'sat-museum+competition')\n",
    "df3 = df_current.loc[df_current.groupby(['year', 'committer_date', 'revision', 'architecture', 'extractor', 'dimacs-transformer'])['dimacs-analyzer-time'].idxmin()]\n",
    "fig, df_stats = plot(df3, x='committer_date', color='facet', legend_position='right', remove_architecture=False)\n",
    "show(fig, width=700, height=default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "fig, _ = plot(df3, x='committer_date', color='facet')\n",
    "fig.update_yaxes(range=[-2.1, 2.6])\n",
    "annotate_solvers(fig, df3[(df3['architecture'] == 'x86')&(df3['extractor'] == 'KConfigReader')&(df3['dimacs-transformer'] == 'KConfigReader')])\n",
    "show(fig, 'all', width=250, height=0.7*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "stats_table(df_stats, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = scope_to(df2, 'FeatureIDE')\n",
    "fig, df_stats = plot(df_current, x='committer_date', facet_col='extractor', facet_row='dimacs-transformer', color='dimacs-analyzer', color_discrete_sequence=generate_gradient(), legend_position='right', remove_architecture=False)\n",
    "stats_table(df_stats)\n",
    "df_current = pd.concat([\n",
    "    df_current[df_current['year-analyzer'].between(2009, 2010)&df_current['year'].between(2009, 2010)],\n",
    "    df_current[df_current['year-analyzer'].between(2011, 2013)&df_current['year'].between(2011, 2013)],\n",
    "    df_current[(df_current['year-analyzer']>=2014)&(df_current['year']>=2014)]  \n",
    "])\n",
    "show(fig, width=1500, height=2*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "fig, df_stats = plot(df_current, x='committer_date', color='facet', legend_position='right', remove_architecture=False)\n",
    "show(fig, width=700, height=default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "fig, _ = plot(df_current, x='committer_date', color='facet')\n",
    "fig.update_yaxes(range=[-2.1, 2.6])\n",
    "show(fig, 'featureide', width=250, height=0.7*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "stats_table(df_stats, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_current = scope_to(df2, 'sat-competition')\n",
    "# df_total_features = df_features.groupby(['extractor', 'revision']).agg({'#total_features': 'min'}).reset_index()\n",
    "# df_total_features = pd.merge(df_kconfig[['committer_date', 'revision']].drop_duplicates(), df_total_features)\n",
    "# print(df_total_features)\n",
    "# df_total_features = pd.merge(df_total_features, df_current)\n",
    "# df_total_features = df_total_features[df_total_features['extractor']=='KClause']\n",
    "# df = df_total_features.sort_values(by='committer_date')\n",
    "# df = df[['dimacs-analyzer-time', 'dimacs-analyzer', '#total_features']].drop_duplicates()\n",
    "# # fig = px.scatter(x=df['#total_features'], y=df['dimacs-analyzer-time'], color=df['dimacs-analyzer'], log_y=True)\n",
    "\n",
    "# # style_scatter(fig, marker_size=3, legend_position=None)\n",
    "# # show(fig, width=3*330, height=310)\n",
    "# df_current\n",
    "\n",
    "df_current = scope_to(df2, 'sat-museum+competition')\n",
    "print(\"median SAT solving time: \" + str(df_current['dimacs-analyzer-time'].median()/1000000000))\n",
    "print(\"percentage of SAT queries over one second: \" + str(100-scipy.stats.percentileofscore(df_current['dimacs-analyzer-time']/1000000000, 1)))\n",
    "print(\"percentage of SAT queries over half a second: \" + str(100-scipy.stats.percentileofscore(df_current['dimacs-analyzer-time']/1000000000, 0.5)))\n",
    "\n",
    "print()\n",
    "print(\"median SAT solving per year:\")\n",
    "for year in range(2002, 2025):\n",
    "    print(f\"{year}: \" + str(df_current[df_current['year']==year]['dimacs-analyzer-time'].median()/1000000000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of experiment_extra.sh\n",
    "print(f\"Statistics for individual solvers\")\n",
    "for query in ['void', '(?:core|dead)', 'core', 'dead', 'partial', 'partial.*\\+.*\\+', 'partial.*\\+.*-', 'partial.*-.*\\+', 'partial.*-.*-']:\n",
    "    df_current = scope_to(df2, 'extra')\n",
    "    df_current = df_current[df_current['query'].str.contains(query)]\n",
    "    df_current['architecture'] = df_current['dimacs-analyzer'].str.contains('sat-museum').map({True: 'Winning', False: 'Non-Winning'})\n",
    "    df_current['extractor'] = df_current['dimacs-analyzer'].str.contains('sat-museum').map({True: 'Winning', False: 'Non-Winning'})\n",
    "    fig, df_stats = plot(df_current, x='committer_date', facet_col='extractor', color='dimacs-analyzer', color_discrete_sequence=generate_gradient(), legend_position='right', remove_architecture=False, extractor_label='Solver Set', extractor_labels=['Winning', 'Non-Winning'], architecture_label='Solver Set', agg='sum')\n",
    "    show(fig, f'extra-{query}', width=1500, height=2*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "    print(f\"Statistics for query '{query}':\")\n",
    "    stats_table(df_stats)\n",
    "    print()\n",
    "\n",
    "print(f\"Statistics for optimal strategy\")\n",
    "for query in ['void', '(?:core|dead)', 'partial']:\n",
    "    df_current = scope_to(df2, 'extra')\n",
    "    df_current = df_current[df_current['query'].str.contains(query)]\n",
    "    df_current['architecture'] = df_current['dimacs-analyzer'].str.contains('sat-museum').map({True: 'Winning', False: 'Non-Winning'})\n",
    "    df_current['extractor'] = df_current['dimacs-analyzer'].str.contains('sat-museum').map({True: 'Winning', False: 'Non-Winning'})\n",
    "    df_sum = (\n",
    "        df_current\n",
    "        .groupby(['year', 'year-analyzer', 'dimacs-analyzer', 'source-analyzer', 'committer_date', 'revision', 'architecture', 'extractor', 'dimacs-transformer'], as_index=False)\n",
    "        .agg(total_time=('dimacs-analyzer-time', 'sum'))\n",
    "    )\n",
    "    df_sum = df_sum.rename(columns={'total_time': 'dimacs-analyzer-time'})\n",
    "    df_sum = df_sum[df_sum['year-analyzer'] <= df_sum['year']]\n",
    "    df3 = df_sum.loc[df_sum.groupby(['year', 'committer_date', 'revision', 'architecture', 'extractor', 'dimacs-transformer'])['dimacs-analyzer-time'].idxmin()]\n",
    "    fig, df_stats = plot(df3, x='committer_date', remove_architecture=False, architecture_labels=['Non-Winning', 'Winning'], agg='sum')\n",
    "    show(fig, width=400, height=0.9*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "    print(f\"Statistics for query '{query}':\")\n",
    "    stats_table(df_stats, ['symbol'])\n",
    "    print()\n",
    "\n",
    "print(f\"Statistics for historic strategy\")\n",
    "for query in ['void', '(?:core|dead)', 'partial']:\n",
    "    df_current = scope_to(df2, 'extra')\n",
    "    df_current = df_current[df_current['query'].str.contains(query)]\n",
    "    df_current['architecture'] = df_current['dimacs-analyzer'].str.contains('sat-museum').map({True: 'Winning', False: 'Non-Winning'})\n",
    "    df_current['extractor'] = df_current['dimacs-analyzer'].str.contains('sat-museum').map({True: 'Winning', False: 'Non-Winning'})\n",
    "    df_sum = (\n",
    "        df_current\n",
    "        .groupby(['year', 'year-analyzer', 'dimacs-analyzer', 'source-analyzer', 'committer_date', 'revision', 'architecture', 'extractor', 'dimacs-transformer'], as_index=False)\n",
    "        .agg(total_time=('dimacs-analyzer-time', 'sum'))\n",
    "    )\n",
    "    df_sum = df_sum.rename(columns={'total_time': 'dimacs-analyzer-time'})\n",
    "    df3 = df_sum.loc[df_sum.groupby(['year', 'committer_date', 'revision', 'architecture', 'extractor', 'dimacs-transformer'])['dimacs-analyzer-time'].idxmin()]\n",
    "    fig, df_stats = plot(df3, x='committer_date', remove_architecture=False, architecture_labels=['Non-Winning', 'Winning'])\n",
    "    show(fig, width=400, height=0.9*default_height, margin=dict(l=0, r=0, t=20, b=0))\n",
    "    print(f\"Statistics for query '{query}':\")\n",
    "    stats_table(df_stats, ['symbol'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of satisfiability results in extra experiment\n",
    "df_current = scope_to(df2, 'extra+timeout')\n",
    "print(len(df_current[df_current['model-satisfiable']==True])/len(df_current))\n",
    "print(len(df_current[df_current['model-satisfiable']==False])/len(df_current))\n",
    "print(len(df_current[df_current['model-satisfiable'].isna()])/len(df_current))\n",
    "# these results indicate that most queries were satisfiable, and only a small amount of features are core/dead\n",
    "# a small portion of queries times out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine correctness of solvers by means of majority voting (ignoring NaN values)\n",
    "# if 22 of 23 solvers agree on (un)satisfiability, we consider the remaining solver to be faulty\n",
    "df_current = scope_to(df2, 'extra')\n",
    "df_inconsistent = (\n",
    "    df_current\n",
    "    .groupby(['revision', 'architecture', 'extractor', 'dimacs-transformer', 'query'])\n",
    "    .agg(\n",
    "        count=('dimacs-analyzer-time', 'count'),\n",
    "        distinct_count=('model-satisfiable', pd.Series.nunique),\n",
    "        distinct_values=('model-satisfiable', lambda x: list(x.unique()))\n",
    "    )\n",
    "    .reset_index()\n",
    "    .query('distinct_count != 1')\n",
    ")\n",
    "df_inconsistent\n",
    "\n",
    "group_cols = ['revision', 'architecture', 'extractor', 'dimacs-transformer', 'query']\n",
    "result_col = 'model-satisfiable'  # your True/False column\n",
    "solver_col = 'dimacs-analyzer'     # your solver column\n",
    "\n",
    "def minority_summary_ignore_nan(g):\n",
    "\n",
    "\n",
    "    g = g if isinstance(g, pd.DataFrame) else pd.DataFrame([g])\n",
    "    \n",
    "    # Only consider non-NaN values for majority/minority\n",
    "    non_nan = g[result_col].dropna()\n",
    "    \n",
    "    if non_nan.nunique() <= 1:\n",
    "        return None  # consistent group or only NaNs\n",
    "\n",
    "    counts = non_nan.value_counts()\n",
    "    majority_value = counts.idxmax()\n",
    "    majority_count = counts.max()\n",
    "    \n",
    "    # Minority values (ignore NaN)\n",
    "    minority_values = [v for v in counts.index if v != majority_value]\n",
    "    if not minority_values:\n",
    "        return None\n",
    "    \n",
    "    minority_rows = g[g[result_col].isin(minority_values)]\n",
    "    minority_count = len(minority_rows)\n",
    "    minority_solvers = ', '.join(minority_rows[solver_col].astype(str))\n",
    "    \n",
    "    # Include all group identifiers in the returned DataFrame\n",
    "    data = {col: g[col].iloc[0] for col in group_cols}  # preserve revision, query, etc.\n",
    "    data.update({\n",
    "        'majority_value': majority_value,\n",
    "        'majority_count': majority_count,\n",
    "        'minority_value': ', '.join(map(str, minority_values)),\n",
    "        'minority_count': minority_count,\n",
    "        'minority_solvers': minority_solvers\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "# Apply per group\n",
    "report = (\n",
    "    df_current\n",
    "    .groupby(group_cols, group_keys=False)\n",
    "    .apply(minority_summary_ignore_nan)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# a manual inspection shows that the only faulty solver is candy-2017\n",
    "\n",
    "# Explode the minority solvers into a flat Series\n",
    "bad_solvers = report['minority_solvers'].str.split(', ').explode()\n",
    "\n",
    "# Keep only rows where the solver is in the bad_solvers\n",
    "df_bad_solvers = df_current[df_current['dimacs-analyzer'].isin(bad_solvers)]\n",
    "\n",
    "# Now filter these rows to only include the groups in report\n",
    "df_bad_calls = df_bad_solvers.merge(\n",
    "    report[['revision', 'architecture', 'extractor', 'dimacs-transformer', 'query']],\n",
    "    on=['revision', 'architecture', 'extractor', 'dimacs-transformer', 'query'],\n",
    "    how='inner'\n",
    ")\n",
    "df_bad_calls\n",
    "df_good_calls = pd.merge(\n",
    "    df_bad_solvers,\n",
    "    df_bad_calls,\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ").query('_merge == \"left_only\"').drop(columns=['_merge'])\n",
    "\n",
    "len(df_bad_calls)/len(df_bad_solvers)\n",
    "# this indicates that all solvers agree on all queries, except for candy-2017, which is faulty in 13.3% of its calls, indicating some kind of solver bug\n",
    "# because it returns correct results in most cases, and does not yield unusual results compared to the other solvers, we keep it in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total time spent in extra experiment\n",
    "print((scope_to(df2, 'extra+timeout')['dimacs-analyzer-time'] / 1000000000).sum()/3600/24)\n",
    "# statistics on typical time spent per SAT call (comparison of winning vs. non-winning solvers)\n",
    "winning = scope_to(df2, 'extra')\n",
    "winning = winning[winning['dimacs-analyzer'].str.contains('sat-museum')]\n",
    "nonwinning = scope_to(df2, 'extra')\n",
    "nonwinning = nonwinning[~nonwinning['dimacs-analyzer'].str.contains('sat-museum')]\n",
    "(nonwinning['dimacs-analyzer-time'] / 1000000000).describe()/(winning['dimacs-analyzer-time'] / 1000000000).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate timeouts in extra experiment\n",
    "df_current=scope_to(df2, 'extra+timeout')\n",
    "df_current=df_current[df_current['model-satisfiable'].isna()]\n",
    "df_current[['revision', 'architecture', 'extractor', 'dimacs-transformer', 'query']]\n",
    "df_current2=scope_to(df2, 'extra')\n",
    "df_current2=pd.merge(\n",
    "    df_current,\n",
    "    df_current2,\n",
    "    on=['revision', 'architecture', 'extractor', 'dimacs-transformer', 'query'],\n",
    "    how='inner'\n",
    ")\n",
    "# the results show that all timeouts from the local search solvers unitwalk and adaptg2wsat2011 are due to unsatisfiable instances, which is to be expected from this kind of solver\n",
    "# yalsat, on the other hand, also times out on satisfiable instances, so these are \"true timeouts\" that we do consider (this is consistent because yalsat is pretty slow overall)\n",
    "print(df_current2[df_current2['dimacs-analyzer_y']=='sat-museum/kissat-2020'][['dimacs-analyzer_x', 'model-satisfiable_y']].groupby(['dimacs-analyzer_x', 'model-satisfiable_y']).size().reset_index(name='count'))\n",
    "# the following confirms that indeed yalsat can successfully detect satisfiable instances\n",
    "df_current=scope_to(df2, 'extra')\n",
    "df_current[df_current['dimacs-analyzer']==' yalsat-2017'].groupby(['model-satisfiable']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiler comparison (omitted for brevity from section 5.3.6)\n",
    "for transformer in ['KConfigReader', 'Z3']:\n",
    "    df_current = pd.concat([scope_to(df2, 'sat-museum'), scope_to(df2, 'sat-competition!=2023!=2024')])\n",
    "    fig, df_stats = plot(df_current[df_current['dimacs-transformer'] == transformer], x='committer_date', facet_col='source-analyzer', facet_row='extractor', color='dimacs-analyzer', color_discrete_sequence=generate_gradient(), legend_position='right', remove_architecture=False)\n",
    "    show(fig, width=1500, height=2*default_height, margin=dict(l=0, r=0, t=20, b=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are solvers getting more complex over time?\n",
    "df_current = df2[~df2['solver_source_lines_of_code'].isna()]\n",
    "fig = px.scatter(\n",
    "    df_current,\n",
    "    x=df_current['solver_source_lines_of_code_extended'],\n",
    "    y=df_current['year-analyzer'],\n",
    "    color='dimacs-analyzer',\n",
    "    labels={\n",
    "        'committer_date': 'Year of Feature Model',\n",
    "        'y': 'SAT Runtime (log<sub>10</sub> s)'\n",
    "    },\n",
    "    hover_data=['revision', 'dimacs-analyzer', 'architecture', 'dimacs-transformer', 'extractor']\n",
    ")\n",
    "show(fig, width=1000, height=2*default_height)\n",
    "\n",
    "# test the hypothesis that smaller solvers (in terms of lines of code) have lower SAT runtime\n",
    "# this does not seem the case (tinisat + black_hole_SAT seem to be outliers)\n",
    "fig = px.box(\n",
    "    df_current,\n",
    "    x=df_current['solver_source_lines_of_code_extended'],\n",
    "    y=df_current['dimacs-analyzer-time'] / 1000000000,\n",
    "    log_y=True,\n",
    "    log_x=True,\n",
    "    color='dimacs-analyzer',\n",
    "    labels={\n",
    "        'committer_date': 'Year of Feature Model',\n",
    "        'y': 'SAT Runtime (log<sub>10</sub> s)'\n",
    "    },\n",
    "    hover_data=['revision', 'dimacs-analyzer', 'architecture', 'dimacs-transformer', 'extractor']\n",
    ")\n",
    "show(fig, width=1000, height=2*default_height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
